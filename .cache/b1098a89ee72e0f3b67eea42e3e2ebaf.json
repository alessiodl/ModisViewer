{"dependencies":[{"name":"../util.js","loc":{"line":17,"column":23}},{"name":"../Disposable.js","loc":{"line":18,"column":23}},{"name":"../obj.js","loc":{"line":19,"column":22}},{"name":"../webgl/ContextEventType.js","loc":{"line":20,"column":29}},{"name":"../transform.js","loc":{"line":21,"column":148}},{"name":"../vec/mat4.js","loc":{"line":22,"column":38}},{"name":"./PostProcessingPass.js","loc":{"line":23,"column":36}},{"name":"../webgl.js","loc":{"line":24,"column":103}},{"name":"../array.js","loc":{"line":25,"column":25}},{"name":"../asserts.js","loc":{"line":26,"column":23}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.AttributeType = exports.DefaultUniform = exports.ShaderType = undefined;\nexports.computeAttributesStride = computeAttributesStride;\n\nvar _util = require(\"../util.js\");\n\nvar _Disposable = require(\"../Disposable.js\");\n\nvar _Disposable2 = _interopRequireDefault(_Disposable);\n\nvar _obj = require(\"../obj.js\");\n\nvar _ContextEventType = require(\"../webgl/ContextEventType.js\");\n\nvar _ContextEventType2 = _interopRequireDefault(_ContextEventType);\n\nvar _transform = require(\"../transform.js\");\n\nvar _mat = require(\"../vec/mat4.js\");\n\nvar _PostProcessingPass = require(\"./PostProcessingPass.js\");\n\nvar _PostProcessingPass2 = _interopRequireDefault(_PostProcessingPass);\n\nvar _webgl = require(\"../webgl.js\");\n\nvar _array = require(\"../array.js\");\n\nvar _asserts = require(\"../asserts.js\");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nvar __extends = undefined && undefined.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n/**\n * @module ol/webgl/Helper\n */\n\n/**\n * @typedef {Object} BufferCacheEntry\n * @property {import(\"./Buffer.js\").default} buffer\n * @property {WebGLBuffer} webGlBuffer\n */\n/**\n * Shader types, either `FRAGMENT_SHADER` or `VERTEX_SHADER`.\n * @enum {number}\n */\nvar ShaderType = exports.ShaderType = {\n  FRAGMENT_SHADER: 0x8B30,\n  VERTEX_SHADER: 0x8B31\n};\n/**\n * Uniform names used in the default shaders: `PROJECTION_MATRIX`, `OFFSET_SCALE_MATRIX`.\n * and `OFFSET_ROTATION_MATRIX`.\n * @enum {string}\n */\nvar DefaultUniform = exports.DefaultUniform = {\n  PROJECTION_MATRIX: 'u_projectionMatrix',\n  OFFSET_SCALE_MATRIX: 'u_offsetScaleMatrix',\n  OFFSET_ROTATION_MATRIX: 'u_offsetRotateMatrix',\n  TIME: 'u_time',\n  ZOOM: 'u_zoom',\n  RESOLUTION: 'u_resolution'\n};\n/**\n * Attribute types, either `UNSIGNED_BYTE`, `UNSIGNED_SHORT`, `UNSIGNED_INT` or `FLOAT`\n * Note: an attribute stored in a `Float32Array` should be of type `FLOAT`.\n * @enum {number}\n */\nvar AttributeType = exports.AttributeType = {\n  UNSIGNED_BYTE: _webgl.UNSIGNED_BYTE,\n  UNSIGNED_SHORT: _webgl.UNSIGNED_SHORT,\n  UNSIGNED_INT: _webgl.UNSIGNED_INT,\n  FLOAT: _webgl.FLOAT\n};\n/**\n * Description of an attribute in a buffer\n * @typedef {Object} AttributeDescription\n * @property {string} name Attribute name to use in shaders\n * @property {number} size Number of components per attributes\n * @property {AttributeType} [type] Attribute type, i.e. number of bytes used to store the value. This is\n * determined by the class of typed array which the buffer uses (eg. `Float32Array` for a `FLOAT` attribute).\n * Default is `FLOAT`.\n */\n/**\n * @typedef {number|Array<number>|HTMLCanvasElement|HTMLImageElement|ImageData|import(\"../transform\").Transform} UniformLiteralValue\n */\n/**\n * Uniform value can be a number, array of numbers (2 to 4), canvas element or a callback returning\n * one of the previous types.\n * @typedef {UniformLiteralValue|function(import(\"../PluggableMap.js\").FrameState):UniformLiteralValue} UniformValue\n */\n/**\n * @typedef {Object} PostProcessesOptions\n * @property {number} [scaleRatio] Scale ratio; if < 1, the post process will render to a texture smaller than\n * the main canvas which will then be sampled up (useful for saving resource on blur steps).\n * @property {string} [vertexShader] Vertex shader source\n * @property {string} [fragmentShader] Fragment shader source\n * @property {Object.<string,UniformValue>} [uniforms] Uniform definitions for the post process step\n */\n/**\n * @typedef {Object} Options\n * @property {Object.<string,UniformValue>} [uniforms] Uniform definitions; property names must match the uniform\n * names in the provided or default shaders.\n * @property {Array<PostProcessesOptions>} [postProcesses] Post-processes definitions\n */\n/**\n * @typedef {Object} UniformInternalDescription\n * @property {string} name Name\n * @property {UniformValue=} value Value\n * @property {WebGLTexture} [texture] Texture\n * @private\n */\n/**\n * @classdesc\n * This class is intended to provide low-level functions related to WebGL rendering, so that accessing\n * directly the WebGL API should not be required anymore.\n *\n * Several operations are handled by the `WebGLHelper` class:\n *\n * ### Define custom shaders and uniforms\n *\n *   *Shaders* are low-level programs executed on the GPU and written in GLSL. There are two types of shaders:\n *\n *   Vertex shaders are used to manipulate the position and attribute of *vertices* of rendered primitives (ie. corners of a square).\n *   Outputs are:\n *\n *   * `gl_Position`: position of the vertex in screen space\n *\n *   * Varyings usually prefixed with `v_` are passed on to the fragment shader\n *\n *   Fragment shaders are used to control the actual color of the pixels drawn on screen. Their only output is `gl_FragColor`.\n *\n *   Both shaders can take *uniforms* or *attributes* as input. Attributes are explained later. Uniforms are common, read-only values that\n *   can be changed at every frame and can be of type float, arrays of float or images.\n *\n *   Shaders must be compiled and assembled into a program like so:\n *   ```js\n *   // here we simply create two shaders and assemble them in a program which is then used\n *   // for subsequent rendering calls\n *   const vertexShader = new WebGLVertex(VERTEX_SHADER);\n *   const fragmentShader = new WebGLFragment(FRAGMENT_SHADER);\n *   const program = this.context.getProgram(fragmentShader, vertexShader);\n *   helper.useProgram(this.program);\n *   ```\n *\n *   Uniforms are defined using the `uniforms` option and can either be explicit values or callbacks taking the frame state as argument.\n *   You can also change their value along the way like so:\n *   ```js\n *   helper.setUniformFloatValue('u_value', valueAsNumber);\n *   ```\n *\n * ### Defining post processing passes\n *\n *   *Post processing* describes the act of rendering primitives to a texture, and then rendering this texture to the final canvas\n *   while applying special effects in screen space.\n *   Typical uses are: blurring, color manipulation, depth of field, filtering...\n *\n *   The `WebGLHelper` class offers the possibility to define post processes at creation time using the `postProcesses` option.\n *   A post process step accepts the following options:\n *\n *   * `fragmentShader` and `vertexShader`: text literals in GLSL language that will be compiled and used in the post processing step.\n *   * `uniforms`: uniforms can be defined for the post processing steps just like for the main render.\n *   * `scaleRatio`: allows using an intermediate texture smaller or higher than the final canvas in the post processing step.\n *     This is typically used in blur steps to reduce the performance overhead by using an already downsampled texture as input.\n *\n *   The {@link module:ol/webgl/PostProcessingPass~WebGLPostProcessingPass} class is used internally, refer to its documentation for more info.\n *\n * ### Binding WebGL buffers and flushing data into them\n *\n *   Data that must be passed to the GPU has to be transferred using {@link module:ol/webgl/Buffer~WebGLArrayBuffer} objects.\n *   A buffer has to be created only once, but must be bound every time the buffer content will be used for rendering.\n *   This is done using {@link bindBuffer}.\n *   When the buffer's array content has changed, the new data has to be flushed to the GPU memory; this is done using\n *   {@link flushBufferData}. Note: this operation is expensive and should be done as infrequently as possible.\n *\n *   When binding an array buffer, a `target` parameter must be given: it should be either {@link module:ol/webgl.ARRAY_BUFFER}\n *   (if the buffer contains vertices data) or {@link module:ol/webgl.ELEMENT_ARRAY_BUFFER} (if the buffer contains indices data).\n *\n *   Examples below:\n *   ```js\n *   // at initialization phase\n *   const verticesBuffer = new WebGLArrayBuffer([], DYNAMIC_DRAW);\n *   const indicesBuffer = new WebGLArrayBuffer([], DYNAMIC_DRAW);\n *\n *   // when array values have changed\n *   helper.flushBufferData(ARRAY_BUFFER, this.verticesBuffer);\n *   helper.flushBufferData(ELEMENT_ARRAY_BUFFER, this.indicesBuffer);\n *\n *   // at rendering phase\n *   helper.bindBuffer(ARRAY_BUFFER, this.verticesBuffer);\n *   helper.bindBuffer(ELEMENT_ARRAY_BUFFER, this.indicesBuffer);\n *   ```\n *\n * ### Specifying attributes\n *\n *   The GPU only receives the data as arrays of numbers. These numbers must be handled differently depending on what it describes (position, texture coordinate...).\n *   Attributes are used to specify these uses. Use {@link enableAttributeArray_} and either\n *   the default attribute names in {@link module:ol/webgl/Helper.DefaultAttrib} or custom ones.\n *\n *   Please note that you will have to specify the type and offset of the attributes in the data array. You can refer to the documentation of [WebGLRenderingContext.vertexAttribPointer](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/vertexAttribPointer) for more explanation.\n *   ```js\n *   // here we indicate that the data array has the following structure:\n *   // [posX, posY, offsetX, offsetY, texCoordU, texCoordV, posX, posY, ...]\n *   helper.enableAttributes([\n *     {\n *        name: 'a_position',\n *        size: 2\n *     },\n *     {\n *       name: 'a_offset',\n *       size: 2\n *     },\n *     {\n *       name: 'a_texCoord',\n *       size: 2\n *     }\n *   ])\n *   ```\n *\n * ### Rendering primitives\n *\n *   Once all the steps above have been achieved, rendering primitives to the screen is done using {@link prepareDraw}, {@link drawElements} and {@link finalizeDraw}.\n *   ```js\n *   // frame preparation step\n *   helper.prepareDraw(frameState);\n *\n *   // call this for every data array that has to be rendered on screen\n *   helper.drawElements(0, this.indicesBuffer.getArray().length);\n *\n *   // finalize the rendering by applying post processes\n *   helper.finalizeDraw(frameState);\n *   ```\n *\n * For an example usage of this class, refer to {@link module:ol/renderer/webgl/PointsLayer~WebGLPointsLayerRenderer}.\n *\n *\n * @api\n */\nvar WebGLHelper = /** @class */function (_super) {\n  __extends(WebGLHelper, _super);\n  /**\n   * @param {Options=} opt_options Options.\n   */\n  function WebGLHelper(opt_options) {\n    var _this = _super.call(this) || this;\n    var options = opt_options || {};\n    /** @private */\n    _this.boundHandleWebGLContextLost_ = _this.handleWebGLContextLost.bind(_this);\n    /** @private */\n    _this.boundHandleWebGLContextRestored_ = _this.handleWebGLContextRestored.bind(_this);\n    /**\n     * @private\n     * @type {HTMLCanvasElement}\n     */\n    _this.canvas_ = document.createElement('canvas');\n    _this.canvas_.style.position = 'absolute';\n    _this.canvas_.style.left = '0';\n    /**\n     * @private\n     * @type {WebGLRenderingContext}\n     */\n    _this.gl_ = (0, _webgl.getContext)(_this.canvas_);\n    var gl = _this.getGL();\n    /**\n     * @private\n     * @type {!Object<string, BufferCacheEntry>}\n     */\n    _this.bufferCache_ = {};\n    /**\n     * @private\n     * @type {WebGLProgram}\n     */\n    _this.currentProgram_ = null;\n    (0, _asserts.assert)((0, _array.includes)((0, _webgl.getSupportedExtensions)(), 'OES_element_index_uint'), 63);\n    gl.getExtension('OES_element_index_uint');\n    _this.canvas_.addEventListener(_ContextEventType2.default.LOST, _this.boundHandleWebGLContextLost_);\n    _this.canvas_.addEventListener(_ContextEventType2.default.RESTORED, _this.boundHandleWebGLContextRestored_);\n    /**\n     * @private\n     * @type {import(\"../transform.js\").Transform}\n     */\n    _this.offsetRotateMatrix_ = (0, _transform.create)();\n    /**\n     * @private\n     * @type {import(\"../transform.js\").Transform}\n     */\n    _this.offsetScaleMatrix_ = (0, _transform.create)();\n    /**\n     * @private\n     * @type {Array<number>}\n     */\n    _this.tmpMat4_ = (0, _mat.create)();\n    /**\n     * @private\n     * @type {Object.<string, WebGLUniformLocation>}\n     */\n    _this.uniformLocations_ = {};\n    /**\n     * @private\n     * @type {Object.<string, number>}\n     */\n    _this.attribLocations_ = {};\n    /**\n     * Holds info about custom uniforms used in the post processing pass.\n     * If the uniform is a texture, the WebGL Texture object will be stored here.\n     * @type {Array<UniformInternalDescription>}\n     * @private\n     */\n    _this.uniforms_ = [];\n    if (options.uniforms) {\n      for (var name_1 in options.uniforms) {\n        _this.uniforms_.push({\n          name: name_1,\n          value: options.uniforms[name_1]\n        });\n      }\n    }\n    /**\n     * An array of PostProcessingPass objects is kept in this variable, built from the steps provided in the\n     * options. If no post process was given, a default one is used (so as not to have to make an exception to\n     * the frame buffer logic).\n     * @type {Array<WebGLPostProcessingPass>}\n     * @private\n     */\n    _this.postProcessPasses_ = options.postProcesses ? options.postProcesses.map(function (options) {\n      return new _PostProcessingPass2.default({\n        webGlContext: gl,\n        scaleRatio: options.scaleRatio,\n        vertexShader: options.vertexShader,\n        fragmentShader: options.fragmentShader,\n        uniforms: options.uniforms\n      });\n    }) : [new _PostProcessingPass2.default({ webGlContext: gl })];\n    /**\n     * @type {string|null}\n     * @private\n     */\n    _this.shaderCompileErrors_ = null;\n    /**\n     * @type {number}\n     * @private\n     */\n    _this.startTime_ = Date.now();\n    return _this;\n  }\n  /**\n   * Just bind the buffer if it's in the cache. Otherwise create\n   * the WebGL buffer, bind it, populate it, and add an entry to\n   * the cache.\n   * @param {import(\"./Buffer\").default} buffer Buffer.\n   * @api\n   */\n  WebGLHelper.prototype.bindBuffer = function (buffer) {\n    var gl = this.getGL();\n    var bufferKey = (0, _util.getUid)(buffer);\n    var bufferCache = this.bufferCache_[bufferKey];\n    if (!bufferCache) {\n      var webGlBuffer = gl.createBuffer();\n      bufferCache = {\n        buffer: buffer,\n        webGlBuffer: webGlBuffer\n      };\n      this.bufferCache_[bufferKey] = bufferCache;\n    }\n    gl.bindBuffer(buffer.getType(), bufferCache.webGlBuffer);\n  };\n  /**\n   * Update the data contained in the buffer array; this is required for the\n   * new data to be rendered\n   * @param {import(\"./Buffer\").default} buffer Buffer.\n   * @api\n   */\n  WebGLHelper.prototype.flushBufferData = function (buffer) {\n    var gl = this.getGL();\n    this.bindBuffer(buffer);\n    gl.bufferData(buffer.getType(), buffer.getArray(), buffer.getUsage());\n  };\n  /**\n   * @param {import(\"./Buffer.js\").default} buf Buffer.\n   */\n  WebGLHelper.prototype.deleteBuffer = function (buf) {\n    var gl = this.getGL();\n    var bufferKey = (0, _util.getUid)(buf);\n    var bufferCacheEntry = this.bufferCache_[bufferKey];\n    if (!gl.isContextLost()) {\n      gl.deleteBuffer(bufferCacheEntry.buffer);\n    }\n    delete this.bufferCache_[bufferKey];\n  };\n  /**\n   * @inheritDoc\n   */\n  WebGLHelper.prototype.disposeInternal = function () {\n    this.canvas_.removeEventListener(_ContextEventType2.default.LOST, this.boundHandleWebGLContextLost_);\n    this.canvas_.removeEventListener(_ContextEventType2.default.RESTORED, this.boundHandleWebGLContextRestored_);\n  };\n  /**\n   * Clear the buffer & set the viewport to draw.\n   * Post process passes will be initialized here, the first one being bound as a render target for\n   * subsequent draw calls.\n   * @param {import(\"../PluggableMap.js\").FrameState} frameState current frame state\n   * @api\n   */\n  WebGLHelper.prototype.prepareDraw = function (frameState) {\n    var gl = this.getGL();\n    var canvas = this.getCanvas();\n    var size = frameState.size;\n    var pixelRatio = frameState.pixelRatio;\n    canvas.width = size[0] * pixelRatio;\n    canvas.height = size[1] * pixelRatio;\n    canvas.style.width = size[0] + 'px';\n    canvas.style.height = size[1] + 'px';\n    gl.useProgram(this.currentProgram_);\n    // loop backwards in post processes list\n    for (var i = this.postProcessPasses_.length - 1; i >= 0; i--) {\n      this.postProcessPasses_[i].init(frameState);\n    }\n    gl.bindTexture(gl.TEXTURE_2D, null);\n    gl.clearColor(0.0, 0.0, 0.0, 0.0);\n    gl.clear(gl.COLOR_BUFFER_BIT);\n    gl.enable(gl.BLEND);\n    gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_ALPHA);\n    gl.useProgram(this.currentProgram_);\n    this.applyFrameState(frameState);\n    this.applyUniforms(frameState);\n  };\n  /**\n   * Clear the render target & bind it for future draw operations.\n   * This is similar to `prepareDraw`, only post processes will not be applied.\n   * Note: the whole viewport will be drawn to the render target, regardless of its size.\n   * @param {import(\"../PluggableMap.js\").FrameState} frameState current frame state\n   * @param {import(\"./RenderTarget.js\").default} renderTarget Render target to draw to\n   * @param {boolean} [opt_disableAlphaBlend] If true, no alpha blending will happen.\n   */\n  WebGLHelper.prototype.prepareDrawToRenderTarget = function (frameState, renderTarget, opt_disableAlphaBlend) {\n    var gl = this.getGL();\n    var size = renderTarget.getSize();\n    gl.bindFramebuffer(gl.FRAMEBUFFER, renderTarget.getFramebuffer());\n    gl.viewport(0, 0, size[0], size[1]);\n    gl.bindTexture(gl.TEXTURE_2D, renderTarget.getTexture());\n    gl.clearColor(0.0, 0.0, 0.0, 0.0);\n    gl.clear(gl.COLOR_BUFFER_BIT);\n    gl.enable(gl.BLEND);\n    gl.blendFunc(gl.ONE, opt_disableAlphaBlend ? gl.ZERO : gl.ONE_MINUS_SRC_ALPHA);\n    gl.useProgram(this.currentProgram_);\n    this.applyFrameState(frameState);\n    this.applyUniforms(frameState);\n  };\n  /**\n   * Execute a draw call based on the currently bound program, texture, buffers, attributes.\n   * @param {number} start Start index.\n   * @param {number} end End index.\n   * @api\n   */\n  WebGLHelper.prototype.drawElements = function (start, end) {\n    var gl = this.getGL();\n    var elementType = gl.UNSIGNED_INT;\n    var elementSize = 4;\n    var numItems = end - start;\n    var offsetInBytes = start * elementSize;\n    gl.drawElements(gl.TRIANGLES, numItems, elementType, offsetInBytes);\n  };\n  /**\n   * Apply the successive post process passes which will eventually render to the actual canvas.\n   * @param {import(\"../PluggableMap.js\").FrameState} frameState current frame state\n   * @api\n   */\n  WebGLHelper.prototype.finalizeDraw = function (frameState) {\n    // apply post processes using the next one as target\n    for (var i = 0; i < this.postProcessPasses_.length; i++) {\n      this.postProcessPasses_[i].apply(frameState, this.postProcessPasses_[i + 1] || null);\n    }\n  };\n  /**\n   * @return {HTMLCanvasElement} Canvas.\n   * @api\n   */\n  WebGLHelper.prototype.getCanvas = function () {\n    return this.canvas_;\n  };\n  /**\n   * Get the WebGL rendering context\n   * @return {WebGLRenderingContext} The rendering context.\n   * @api\n   */\n  WebGLHelper.prototype.getGL = function () {\n    return this.gl_;\n  };\n  /**\n   * Sets the default matrix uniforms for a given frame state. This is called internally in `prepareDraw`.\n   * @param {import(\"../PluggableMap.js\").FrameState} frameState Frame state.\n   * @private\n   */\n  WebGLHelper.prototype.applyFrameState = function (frameState) {\n    var size = frameState.size;\n    var rotation = frameState.viewState.rotation;\n    var offsetScaleMatrix = (0, _transform.reset)(this.offsetScaleMatrix_);\n    (0, _transform.scale)(offsetScaleMatrix, 2 / size[0], 2 / size[1]);\n    var offsetRotateMatrix = (0, _transform.reset)(this.offsetRotateMatrix_);\n    if (rotation !== 0) {\n      (0, _transform.rotate)(offsetRotateMatrix, -rotation);\n    }\n    this.setUniformMatrixValue(DefaultUniform.OFFSET_SCALE_MATRIX, (0, _mat.fromTransform)(this.tmpMat4_, offsetScaleMatrix));\n    this.setUniformMatrixValue(DefaultUniform.OFFSET_ROTATION_MATRIX, (0, _mat.fromTransform)(this.tmpMat4_, offsetRotateMatrix));\n    this.setUniformFloatValue(DefaultUniform.TIME, (Date.now() - this.startTime_) * 0.001);\n    this.setUniformFloatValue(DefaultUniform.ZOOM, frameState.viewState.zoom);\n    this.setUniformFloatValue(DefaultUniform.RESOLUTION, frameState.viewState.resolution);\n  };\n  /**\n   * Sets the custom uniforms based on what was given in the constructor. This is called internally in `prepareDraw`.\n   * @param {import(\"../PluggableMap.js\").FrameState} frameState Frame state.\n   * @private\n   */\n  WebGLHelper.prototype.applyUniforms = function (frameState) {\n    var gl = this.getGL();\n    var value;\n    var textureSlot = 0;\n    this.uniforms_.forEach(function (uniform) {\n      value = typeof uniform.value === 'function' ? uniform.value(frameState) : uniform.value;\n      // apply value based on type\n      if (value instanceof HTMLCanvasElement || value instanceof HTMLImageElement || value instanceof ImageData) {\n        // create a texture & put data\n        if (!uniform.texture) {\n          uniform.texture = gl.createTexture();\n        }\n        gl.activeTexture(gl[\"TEXTURE\" + textureSlot]);\n        gl.bindTexture(gl.TEXTURE_2D, uniform.texture);\n        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n        var imageReady = !(value instanceof HTMLImageElement) || /** @type {HTMLImageElement} */value.complete;\n        if (imageReady) {\n          gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, value);\n        }\n        // fill texture slots by increasing index\n        gl.uniform1i(this.getUniformLocation(uniform.name), textureSlot++);\n      } else if (Array.isArray(value) && value.length === 6) {\n        this.setUniformMatrixValue(uniform.name, (0, _mat.fromTransform)(this.tmpMat4_, value));\n      } else if (Array.isArray(value) && value.length <= 4) {\n        switch (value.length) {\n          case 2:\n            gl.uniform2f(this.getUniformLocation(uniform.name), value[0], value[1]);\n            return;\n          case 3:\n            gl.uniform3f(this.getUniformLocation(uniform.name), value[0], value[1], value[2]);\n            return;\n          case 4:\n            gl.uniform4f(this.getUniformLocation(uniform.name), value[0], value[1], value[2], value[3]);\n            return;\n          default:\n            return;\n        }\n      } else if (typeof value === 'number') {\n        gl.uniform1f(this.getUniformLocation(uniform.name), value);\n      }\n    }.bind(this));\n  };\n  /**\n   * Use a program.  If the program is already in use, this will return `false`.\n   * @param {WebGLProgram} program Program.\n   * @return {boolean} Changed.\n   * @api\n   */\n  WebGLHelper.prototype.useProgram = function (program) {\n    if (program == this.currentProgram_) {\n      return false;\n    } else {\n      var gl = this.getGL();\n      gl.useProgram(program);\n      this.currentProgram_ = program;\n      this.uniformLocations_ = {};\n      this.attribLocations_ = {};\n      return true;\n    }\n  };\n  /**\n   * Will attempt to compile a vertex or fragment shader based on source\n   * On error, the shader will be returned but\n   * `gl.getShaderParameter(shader, gl.COMPILE_STATUS)` will return `true`\n   * Use `gl.getShaderInfoLog(shader)` to have details\n   * @param {string} source Shader source\n   * @param {ShaderType} type VERTEX_SHADER or FRAGMENT_SHADER\n   * @return {WebGLShader} Shader object\n   */\n  WebGLHelper.prototype.compileShader = function (source, type) {\n    var gl = this.getGL();\n    var shader = gl.createShader(type);\n    gl.shaderSource(shader, source);\n    gl.compileShader(shader);\n    return shader;\n  };\n  /**\n   * Create a program for a vertex and fragment shader. The shaders compilation may have failed:\n   * use `WebGLHelper.getShaderCompileErrors()`to have details if any.\n   * @param {string} fragmentShaderSource Fragment shader source.\n   * @param {string} vertexShaderSource Vertex shader source.\n   * @return {WebGLProgram} Program\n   * @api\n   */\n  WebGLHelper.prototype.getProgram = function (fragmentShaderSource, vertexShaderSource) {\n    var gl = this.getGL();\n    var fragmentShader = this.compileShader(fragmentShaderSource, gl.FRAGMENT_SHADER);\n    var vertexShader = this.compileShader(vertexShaderSource, gl.VERTEX_SHADER);\n    this.shaderCompileErrors_ = null;\n    if (gl.getShaderInfoLog(fragmentShader)) {\n      this.shaderCompileErrors_ = \"Fragment shader compilation failed:\\n\" + gl.getShaderInfoLog(fragmentShader);\n    }\n    if (gl.getShaderInfoLog(vertexShader)) {\n      this.shaderCompileErrors_ = (this.shaderCompileErrors_ || '') + (\"Vertex shader compilation failed:\\n\" + gl.getShaderInfoLog(vertexShader));\n    }\n    var program = gl.createProgram();\n    gl.attachShader(program, fragmentShader);\n    gl.attachShader(program, vertexShader);\n    gl.linkProgram(program);\n    return program;\n  };\n  /**\n   * Will return the last shader compilation errors. If no error happened, will return null;\n   * @return {string|null} Errors description, or null if last compilation was successful\n   * @api\n   */\n  WebGLHelper.prototype.getShaderCompileErrors = function () {\n    return this.shaderCompileErrors_;\n  };\n  /**\n   * Will get the location from the shader or the cache\n   * @param {string} name Uniform name\n   * @return {WebGLUniformLocation} uniformLocation\n   * @api\n   */\n  WebGLHelper.prototype.getUniformLocation = function (name) {\n    if (this.uniformLocations_[name] === undefined) {\n      this.uniformLocations_[name] = this.getGL().getUniformLocation(this.currentProgram_, name);\n    }\n    return this.uniformLocations_[name];\n  };\n  /**\n   * Will get the location from the shader or the cache\n   * @param {string} name Attribute name\n   * @return {number} attribLocation\n   * @api\n   */\n  WebGLHelper.prototype.getAttributeLocation = function (name) {\n    if (this.attribLocations_[name] === undefined) {\n      this.attribLocations_[name] = this.getGL().getAttribLocation(this.currentProgram_, name);\n    }\n    return this.attribLocations_[name];\n  };\n  /**\n   * Modifies the given transform to apply the rotation/translation/scaling of the given frame state.\n   * The resulting transform can be used to convert world space coordinates to view coordinates.\n   * @param {import(\"../PluggableMap.js\").FrameState} frameState Frame state.\n   * @param {import(\"../transform\").Transform} transform Transform to update.\n   * @return {import(\"../transform\").Transform} The updated transform object.\n   * @api\n   */\n  WebGLHelper.prototype.makeProjectionTransform = function (frameState, transform) {\n    var size = frameState.size;\n    var rotation = frameState.viewState.rotation;\n    var resolution = frameState.viewState.resolution;\n    var center = frameState.viewState.center;\n    (0, _transform.reset)(transform);\n    (0, _transform.compose)(transform, 0, 0, 2 / (resolution * size[0]), 2 / (resolution * size[1]), -rotation, -center[0], -center[1]);\n    return transform;\n  };\n  /**\n   * Give a value for a standard float uniform\n   * @param {string} uniform Uniform name\n   * @param {number} value Value\n   * @api\n   */\n  WebGLHelper.prototype.setUniformFloatValue = function (uniform, value) {\n    this.getGL().uniform1f(this.getUniformLocation(uniform), value);\n  };\n  /**\n   * Give a value for a standard matrix4 uniform\n   * @param {string} uniform Uniform name\n   * @param {Array<number>} value Matrix value\n   * @api\n   */\n  WebGLHelper.prototype.setUniformMatrixValue = function (uniform, value) {\n    this.getGL().uniformMatrix4fv(this.getUniformLocation(uniform), false, value);\n  };\n  /**\n   * Will set the currently bound buffer to an attribute of the shader program. Used by `#enableAttributes`\n   * internally.\n   * @param {string} attribName Attribute name\n   * @param {number} size Number of components per attributes\n   * @param {number} type UNSIGNED_INT, UNSIGNED_BYTE, UNSIGNED_SHORT or FLOAT\n   * @param {number} stride Stride in bytes (0 means attribs are packed)\n   * @param {number} offset Offset in bytes\n   * @private\n   */\n  WebGLHelper.prototype.enableAttributeArray_ = function (attribName, size, type, stride, offset) {\n    var location = this.getAttributeLocation(attribName);\n    // the attribute has not been found in the shaders; do not enable it\n    if (location < 0) {\n      return;\n    }\n    this.getGL().enableVertexAttribArray(location);\n    this.getGL().vertexAttribPointer(location, size, type, false, stride, offset);\n  };\n  /**\n   * Will enable the following attributes to be read from the currently bound buffer,\n   * i.e. tell the GPU where to read the different attributes in the buffer. An error in the\n   * size/type/order of attributes will most likely break the rendering and throw a WebGL exception.\n   * @param {Array<AttributeDescription>} attributes Ordered list of attributes to read from the buffer\n   * @api\n   */\n  WebGLHelper.prototype.enableAttributes = function (attributes) {\n    var stride = computeAttributesStride(attributes);\n    var offset = 0;\n    for (var i = 0; i < attributes.length; i++) {\n      var attr = attributes[i];\n      this.enableAttributeArray_(attr.name, attr.size, attr.type || _webgl.FLOAT, stride, offset);\n      offset += attr.size * getByteSizeFromType(attr.type);\n    }\n  };\n  /**\n   * WebGL context was lost\n   * @private\n   */\n  WebGLHelper.prototype.handleWebGLContextLost = function () {\n    (0, _obj.clear)(this.bufferCache_);\n    this.currentProgram_ = null;\n  };\n  /**\n   * WebGL context was restored\n   * @private\n   */\n  WebGLHelper.prototype.handleWebGLContextRestored = function () {};\n  /**\n   * Will create or reuse a given webgl texture and apply the given size. If no image data\n   * specified, the texture will be empty, otherwise image data will be used and the `size`\n   * parameter will be ignored.\n   * Note: wrap parameters are set to clamp to edge, min filter is set to linear.\n   * @param {Array<number>} size Expected size of the texture\n   * @param {ImageData|HTMLImageElement|HTMLCanvasElement} [opt_data] Image data/object to bind to the texture\n   * @param {WebGLTexture} [opt_texture] Existing texture to reuse\n   * @return {WebGLTexture} The generated texture\n   * @api\n   */\n  WebGLHelper.prototype.createTexture = function (size, opt_data, opt_texture) {\n    var gl = this.getGL();\n    var texture = opt_texture || gl.createTexture();\n    // set params & size\n    var level = 0;\n    var internalFormat = gl.RGBA;\n    var border = 0;\n    var format = gl.RGBA;\n    var type = gl.UNSIGNED_BYTE;\n    gl.bindTexture(gl.TEXTURE_2D, texture);\n    if (opt_data) {\n      gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, format, type, opt_data);\n    } else {\n      gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, size[0], size[1], border, format, type, null);\n    }\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n    return texture;\n  };\n  return WebGLHelper;\n}(_Disposable2.default);\n/**\n * Compute a stride in bytes based on a list of attributes\n * @param {Array<AttributeDescription>} attributes Ordered list of attributes\n * @returns {number} Stride, ie amount of values for each vertex in the vertex buffer\n * @api\n */\nfunction computeAttributesStride(attributes) {\n  var stride = 0;\n  for (var i = 0; i < attributes.length; i++) {\n    var attr = attributes[i];\n    stride += attr.size * getByteSizeFromType(attr.type);\n  }\n  return stride;\n}\n/**\n * Computes the size in byte of an attribute type.\n * @param {AttributeType} type Attribute type\n * @returns {number} The size in bytes\n */\nfunction getByteSizeFromType(type) {\n  switch (type) {\n    case AttributeType.UNSIGNED_BYTE:\n      return Uint8Array.BYTES_PER_ELEMENT;\n    case AttributeType.UNSIGNED_SHORT:\n      return Uint16Array.BYTES_PER_ELEMENT;\n    case AttributeType.UNSIGNED_INT:\n      return Uint32Array.BYTES_PER_ELEMENT;\n    case AttributeType.FLOAT:\n    default:\n      return Float32Array.BYTES_PER_ELEMENT;\n  }\n}\nexports.default = WebGLHelper;\n//# sourceMappingURL=Helper.js.map"},"hash":"fbc5a081cf97004bf444a4854e08f104"}