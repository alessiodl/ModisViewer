{"dependencies":[{"name":"../../webgl/Buffer.js","loc":{"line":17,"column":29}},{"name":"../../webgl.js","loc":{"line":18,"column":65}},{"name":"../../webgl/Helper.js","loc":{"line":19,"column":46}},{"name":"../../geom/GeometryType.js","loc":{"line":20,"column":25}},{"name":"./Layer.js","loc":{"line":21,"column":89}},{"name":"../../ViewHint.js","loc":{"line":22,"column":21}},{"name":"../../extent.js","loc":{"line":23,"column":44}},{"name":"../../transform.js","loc":{"line":24,"column":135}},{"name":"../../worker/webgl.js","loc":{"line":25,"column":44}},{"name":"../../util.js","loc":{"line":26,"column":23}},{"name":"../../webgl/RenderTarget.js","loc":{"line":27,"column":30}},{"name":"../../asserts.js","loc":{"line":28,"column":23}},{"name":"../../layer/BaseVector.js","loc":{"line":29,"column":23}},{"name":"../../events.js","loc":{"line":30,"column":38}},{"name":"../../source/VectorEventType.js","loc":{"line":31,"column":28}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _Buffer = require(\"../../webgl/Buffer.js\");\n\nvar _Buffer2 = _interopRequireDefault(_Buffer);\n\nvar _webgl = require(\"../../webgl.js\");\n\nvar _Helper = require(\"../../webgl/Helper.js\");\n\nvar _GeometryType = require(\"../../geom/GeometryType.js\");\n\nvar _GeometryType2 = _interopRequireDefault(_GeometryType);\n\nvar _Layer = require(\"./Layer.js\");\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nvar _ViewHint = require(\"../../ViewHint.js\");\n\nvar _ViewHint2 = _interopRequireDefault(_ViewHint);\n\nvar _extent = require(\"../../extent.js\");\n\nvar _transform = require(\"../../transform.js\");\n\nvar _webgl2 = require(\"../../worker/webgl.js\");\n\nvar _util = require(\"../../util.js\");\n\nvar _RenderTarget = require(\"../../webgl/RenderTarget.js\");\n\nvar _RenderTarget2 = _interopRequireDefault(_RenderTarget);\n\nvar _asserts = require(\"../../asserts.js\");\n\nvar _BaseVector = require(\"../../layer/BaseVector.js\");\n\nvar _BaseVector2 = _interopRequireDefault(_BaseVector);\n\nvar _events = require(\"../../events.js\");\n\nvar _VectorEventType = require(\"../../source/VectorEventType.js\");\n\nvar _VectorEventType2 = _interopRequireDefault(_VectorEventType);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nvar __extends = undefined && undefined.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n/**\n * @module ol/renderer/webgl/PointsLayer\n */\n\n/**\n * @typedef {Object} CustomAttribute A description of a custom attribute to be passed on to the GPU, with a value different\n * for each feature.\n * @property {string} name Attribute name.\n * @property {function(import(\"../../Feature\").default, Object<string, *>):number} callback This callback computes the numerical value of the\n * attribute for a given feature (properties are available as 2nd arg for quicker access).\n */\n/**\n * @typedef {Object} FeatureCacheItem Object that holds a reference to a feature, its geometry and properties. Used to optimize\n * rebuildBuffers by accessing these objects quicker.\n * @property {import(\"../../Feature\").default} feature Feature\n * @property {Object<string, *>} properties Feature properties\n * @property {import(\"../../geom\").Geometry} geometry Feature geometry\n */\n/**\n * @typedef {Object} Options\n * @property {Array<CustomAttribute>} [attributes] These attributes will be read from the features in the source and then\n * passed to the GPU. The `name` property of each attribute will serve as its identifier:\n *  * In the vertex shader as an `attribute` by prefixing it with `a_`\n *  * In the fragment shader as a `varying` by prefixing it with `v_`\n * Please note that these can only be numerical values.\n * @property {string} vertexShader Vertex shader source, mandatory.\n * @property {string} fragmentShader Fragment shader source, mandatory.\n * @property {string} [hitVertexShader] Vertex shader source for hit detection rendering.\n * @property {string} [hitFragmentShader] Fragment shader source for hit detection rendering.\n * @property {Object.<string,import(\"../../webgl/Helper\").UniformValue>} [uniforms] Uniform definitions for the post process steps\n * Please note that `u_texture` is reserved for the main texture slot.\n * @property {Array<import(\"./Layer\").PostProcessesOptions>} [postProcesses] Post-processes definitions\n */\n/**\n * @classdesc\n * WebGL vector renderer optimized for points.\n * All features will be rendered as quads (two triangles forming a square). New data will be flushed to the GPU\n * every time the vector source changes.\n *\n * You need to provide vertex and fragment shaders for rendering. This can be done using\n * {@link module:ol/webgl/ShaderBuilder} utilities. These shaders shall expect a `a_position` attribute\n * containing the screen-space projected center of the quad, as well as a `a_index` attribute\n * whose value (0, 1, 2 or 3) indicates which quad vertex is currently getting processed (see structure below).\n *\n * To include variable attributes in the shaders, you need to declare them using the `attributes` property of\n * the options object like so:\n * ```js\n * new WebGLPointsLayerRenderer(layer, {\n *   attributes: [\n *     {\n *       name: 'size',\n *       callback: function(feature) {\n *         // compute something with the feature\n *       }\n *     },\n *     {\n *       name: 'weight',\n *       callback: function(feature) {\n *         // compute something with the feature\n *       }\n *     },\n *   ],\n *   vertexShader:\n *     // shader using attribute a_weight and a_size\n *   fragmentShader:\n *     // shader using varying v_weight and v_size\n * ```\n *\n * To enable hit detection, you must as well provide dedicated shaders using the `hitVertexShader`\n * and `hitFragmentShader` properties. These shall expect the `a_hitColor` attribute to contain\n * the final color that will have to be output for hit detection to work.\n *\n * The following uniform is used for the main texture: `u_texture`.\n *\n * Please note that the main shader output should have premultiplied alpha, otherwise visual anomalies may occur.\n *\n * Points are rendered as quads with the following structure:\n *\n * ```\n *   (u0, v1)      (u1, v1)\n *  [3]----------[2]\n *   |`           |\n *   |  `         |\n *   |    `       |\n *   |      `     |\n *   |        `   |\n *   |          ` |\n *  [0]----------[1]\n *   (u0, v0)      (u1, v0)\n *  ```\n *\n * This uses {@link module:ol/webgl/Helper~WebGLHelper} internally.\n *\n * @api\n */\nvar WebGLPointsLayerRenderer = /** @class */function (_super) {\n  __extends(WebGLPointsLayerRenderer, _super);\n  /**\n   * @param {import(\"../../layer/Layer.js\").default} layer Layer.\n   * @param {Options} options Options.\n   */\n  function WebGLPointsLayerRenderer(layer, options) {\n    var _this = this;\n    var uniforms = options.uniforms || {};\n    var projectionMatrixTransform = (0, _transform.create)();\n    uniforms[_Helper.DefaultUniform.PROJECTION_MATRIX] = projectionMatrixTransform;\n    _this = _super.call(this, layer, {\n      uniforms: uniforms,\n      postProcesses: options.postProcesses\n    }) || this;\n    _this.sourceRevision_ = -1;\n    _this.verticesBuffer_ = new _Buffer2.default(_webgl.ARRAY_BUFFER, _webgl.DYNAMIC_DRAW);\n    _this.hitVerticesBuffer_ = new _Buffer2.default(_webgl.ARRAY_BUFFER, _webgl.DYNAMIC_DRAW);\n    _this.indicesBuffer_ = new _Buffer2.default(_webgl.ELEMENT_ARRAY_BUFFER, _webgl.DYNAMIC_DRAW);\n    _this.program_ = _this.helper.getProgram(options.fragmentShader, options.vertexShader);\n    if (_this.getShaderCompileErrors()) {\n      throw new Error(_this.getShaderCompileErrors());\n    }\n    /**\n     * @type {boolean}\n     * @private\n     */\n    _this.hitDetectionEnabled_ = options.hitFragmentShader && options.hitVertexShader ? true : false;\n    _this.hitProgram_ = _this.hitDetectionEnabled_ && _this.helper.getProgram(options.hitFragmentShader, options.hitVertexShader);\n    if (_this.getShaderCompileErrors()) {\n      throw new Error(_this.getShaderCompileErrors());\n    }\n    var customAttributes = options.attributes ? options.attributes.map(function (attribute) {\n      return {\n        name: 'a_' + attribute.name,\n        size: 1,\n        type: _Helper.AttributeType.FLOAT\n      };\n    }) : [];\n    /**\n     * A list of attributes used by the renderer. By default only the position and\n     * index of the vertex (0 to 3) are required.\n     * @type {Array<import('../../webgl/Helper.js').AttributeDescription>}\n     */\n    _this.attributes = [{\n      name: 'a_position',\n      size: 2,\n      type: _Helper.AttributeType.FLOAT\n    }, {\n      name: 'a_index',\n      size: 1,\n      type: _Helper.AttributeType.FLOAT\n    }].concat(customAttributes);\n    /**\n     * A list of attributes used for hit detection.\n     * @type {Array<import('../../webgl/Helper.js').AttributeDescription>}\n     */\n    _this.hitDetectionAttributes = [{\n      name: 'a_position',\n      size: 2,\n      type: _Helper.AttributeType.FLOAT\n    }, {\n      name: 'a_index',\n      size: 1,\n      type: _Helper.AttributeType.FLOAT\n    }, {\n      name: 'a_hitColor',\n      size: 4,\n      type: _Helper.AttributeType.FLOAT\n    }, {\n      name: 'a_featureUid',\n      size: 1,\n      type: _Helper.AttributeType.FLOAT\n    }].concat(customAttributes);\n    _this.customAttributes = options.attributes ? options.attributes : [];\n    _this.previousExtent_ = (0, _extent.createEmpty)();\n    /**\n     * This transform is updated on every frame and is the composition of:\n     * - invert of the world->screen transform that was used when rebuilding buffers (see `this.renderTransform_`)\n     * - current world->screen transform\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n    _this.currentTransform_ = projectionMatrixTransform;\n    /**\n     * This transform is updated when buffers are rebuilt and converts world space coordinates to screen space\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n    _this.renderTransform_ = (0, _transform.create)();\n    /**\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n    _this.invertRenderTransform_ = (0, _transform.create)();\n    /**\n     * @type {Float32Array}\n     * @private\n     */\n    _this.renderInstructions_ = new Float32Array(0);\n    /**\n     * These instructions are used for hit detection\n     * @type {Float32Array}\n     * @private\n     */\n    _this.hitRenderInstructions_ = new Float32Array(0);\n    /**\n     * @type {WebGLRenderTarget}\n     * @private\n     */\n    _this.hitRenderTarget_ = _this.hitDetectionEnabled_ && new _RenderTarget2.default(_this.helper);\n    _this.worker_ = (0, _webgl2.create)();\n    _this.worker_.addEventListener('message', function (event) {\n      var received = event.data;\n      if (received.type === _Layer.WebGLWorkerMessageType.GENERATE_BUFFERS) {\n        var projectionTransform = received.projectionTransform;\n        if (received.hitDetection) {\n          this.hitVerticesBuffer_.fromArrayBuffer(received.vertexBuffer);\n          this.helper.flushBufferData(this.hitVerticesBuffer_);\n        } else {\n          this.verticesBuffer_.fromArrayBuffer(received.vertexBuffer);\n          this.helper.flushBufferData(this.verticesBuffer_);\n        }\n        this.indicesBuffer_.fromArrayBuffer(received.indexBuffer);\n        this.helper.flushBufferData(this.indicesBuffer_);\n        this.renderTransform_ = projectionTransform;\n        (0, _transform.makeInverse)(this.invertRenderTransform_, this.renderTransform_);\n        if (received.hitDetection) {\n          this.hitRenderInstructions_ = new Float32Array(event.data.renderInstructions);\n        } else {\n          this.renderInstructions_ = new Float32Array(event.data.renderInstructions);\n        }\n        this.getLayer().changed();\n      }\n    }.bind(_this));\n    /**\n     * This object will be updated when the source changes. Key is uid.\n     * @type {Object<string, FeatureCacheItem>}\n     * @private\n     */\n    _this.featureCache_ = {};\n    /**\n     * Amount of features in the cache.\n     * @type {number}\n     * @private\n     */\n    _this.featureCount_ = 0;\n    var source = _this.getLayer().getSource();\n    _this.sourceListenKeys_ = [(0, _events.listen)(source, _VectorEventType2.default.ADDFEATURE, _this.handleSourceFeatureAdded_, _this), (0, _events.listen)(source, _VectorEventType2.default.CHANGEFEATURE, _this.handleSourceFeatureChanged_, _this), (0, _events.listen)(source, _VectorEventType2.default.REMOVEFEATURE, _this.handleSourceFeatureDelete_, _this)];\n    source.forEachFeature(function (feature) {\n      this.featureCache_[(0, _util.getUid)(feature)] = {\n        feature: feature,\n        properties: feature.getProperties(),\n        geometry: feature.getGeometry()\n      };\n      this.featureCount_++;\n    }.bind(_this));\n    return _this;\n  }\n  /**\n   * @param {import(\"../../source/Vector.js\").VectorSourceEvent} event Event.\n   * @private\n   */\n  WebGLPointsLayerRenderer.prototype.handleSourceFeatureAdded_ = function (event) {\n    var feature = event.feature;\n    this.featureCache_[(0, _util.getUid)(feature)] = {\n      feature: feature,\n      properties: feature.getProperties(),\n      geometry: feature.getGeometry()\n    };\n    this.featureCount_++;\n  };\n  /**\n   * @param {import(\"../../source/Vector.js\").VectorSourceEvent} event Event.\n   * @private\n   */\n  WebGLPointsLayerRenderer.prototype.handleSourceFeatureChanged_ = function (event) {\n    var feature = event.feature;\n    this.featureCache_[(0, _util.getUid)(feature)] = {\n      feature: feature,\n      properties: feature.getProperties(),\n      geometry: feature.getGeometry()\n    };\n  };\n  /**\n   * @param {import(\"../../source/Vector.js\").VectorSourceEvent} event Event.\n   * @private\n   */\n  WebGLPointsLayerRenderer.prototype.handleSourceFeatureDelete_ = function (event) {\n    var feature = event.feature;\n    delete this.featureCache_[(0, _util.getUid)(feature)];\n    this.featureCount_--;\n  };\n  /**\n   * @inheritDoc\n   */\n  WebGLPointsLayerRenderer.prototype.renderFrame = function (frameState) {\n    var renderCount = this.indicesBuffer_.getSize();\n    this.helper.drawElements(0, renderCount);\n    this.helper.finalizeDraw(frameState);\n    var canvas = this.helper.getCanvas();\n    var layerState = frameState.layerStatesArray[frameState.layerIndex];\n    var opacity = layerState.opacity;\n    if (opacity !== parseFloat(canvas.style.opacity)) {\n      canvas.style.opacity = opacity;\n    }\n    if (this.hitDetectionEnabled_) {\n      this.renderHitDetection(frameState);\n      this.hitRenderTarget_.clearCachedData();\n    }\n    return canvas;\n  };\n  /**\n   * @inheritDoc\n   */\n  WebGLPointsLayerRenderer.prototype.prepareFrame = function (frameState) {\n    var layer = this.getLayer();\n    var vectorSource = layer.getSource();\n    var viewState = frameState.viewState;\n    var viewNotMoving = !frameState.viewHints[_ViewHint2.default.ANIMATING] && !frameState.viewHints[_ViewHint2.default.INTERACTING];\n    var extentChanged = !(0, _extent.equals)(this.previousExtent_, frameState.extent);\n    var sourceChanged = this.sourceRevision_ < vectorSource.getRevision();\n    if (sourceChanged) {\n      this.sourceRevision_ = vectorSource.getRevision();\n    }\n    if (viewNotMoving && (extentChanged || sourceChanged)) {\n      var projection = viewState.projection;\n      var resolution = viewState.resolution;\n      var renderBuffer = layer instanceof _BaseVector2.default ? layer.getRenderBuffer() : 0;\n      var extent = (0, _extent.buffer)(frameState.extent, renderBuffer * resolution);\n      vectorSource.loadFeatures(extent, resolution, projection);\n      this.rebuildBuffers_(frameState);\n      this.previousExtent_ = frameState.extent.slice();\n    }\n    // apply the current projection transform with the invert of the one used to fill buffers\n    this.helper.makeProjectionTransform(frameState, this.currentTransform_);\n    (0, _transform.multiply)(this.currentTransform_, this.invertRenderTransform_);\n    this.helper.useProgram(this.program_);\n    this.helper.prepareDraw(frameState);\n    // write new data\n    this.helper.bindBuffer(this.verticesBuffer_);\n    this.helper.bindBuffer(this.indicesBuffer_);\n    this.helper.enableAttributes(this.attributes);\n    return true;\n  };\n  /**\n   * Rebuild internal webgl buffers based on current view extent; costly, should not be called too much\n   * @param {import(\"../../PluggableMap\").FrameState} frameState Frame state.\n   * @private\n   */\n  WebGLPointsLayerRenderer.prototype.rebuildBuffers_ = function (frameState) {\n    // saves the projection transform for the current frame state\n    var projectionTransform = (0, _transform.create)();\n    this.helper.makeProjectionTransform(frameState, projectionTransform);\n    // here we anticipate the amount of render instructions that we well generate\n    // this can be done since we know that for normal render we only have x, y as base instructions,\n    // and x, y, r, g, b, a and featureUid for hit render instructions\n    // and we also know the amount of custom attributes to append to these\n    var totalInstructionsCount = (2 + this.customAttributes.length) * this.featureCount_;\n    if (!this.renderInstructions_ || this.renderInstructions_.length !== totalInstructionsCount) {\n      this.renderInstructions_ = new Float32Array(totalInstructionsCount);\n    }\n    if (this.hitDetectionEnabled_) {\n      var totalHitInstructionsCount = (7 + this.customAttributes.length) * this.featureCount_;\n      if (!this.hitRenderInstructions_ || this.hitRenderInstructions_.length !== totalHitInstructionsCount) {\n        this.hitRenderInstructions_ = new Float32Array(totalHitInstructionsCount);\n      }\n    }\n    // loop on features to fill the buffer\n    var featureCache, geometry;\n    var tmpCoords = [];\n    var tmpColor = [];\n    var renderIndex = 0;\n    var hitIndex = 0;\n    var hitColor;\n    for (var featureUid in this.featureCache_) {\n      featureCache = this.featureCache_[featureUid];\n      geometry = /** @type {import(\"../../geom\").Point} */featureCache.geometry;\n      if (!geometry || geometry.getType() !== _GeometryType2.default.POINT) {\n        continue;\n      }\n      tmpCoords[0] = geometry.getFlatCoordinates()[0];\n      tmpCoords[1] = geometry.getFlatCoordinates()[1];\n      (0, _transform.apply)(projectionTransform, tmpCoords);\n      hitColor = (0, _Layer.colorEncodeId)(hitIndex + 6, tmpColor);\n      this.renderInstructions_[renderIndex++] = tmpCoords[0];\n      this.renderInstructions_[renderIndex++] = tmpCoords[1];\n      // for hit detection, the feature uid is saved in the opacity value\n      // and the index of the opacity value is encoded in the color values\n      if (this.hitDetectionEnabled_) {\n        this.hitRenderInstructions_[hitIndex++] = tmpCoords[0];\n        this.hitRenderInstructions_[hitIndex++] = tmpCoords[1];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[0];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[1];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[2];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[3];\n        this.hitRenderInstructions_[hitIndex++] = Number(featureUid);\n      }\n      // pushing custom attributes\n      var value = void 0;\n      for (var j = 0; j < this.customAttributes.length; j++) {\n        value = this.customAttributes[j].callback(featureCache.feature, featureCache.properties);\n        this.renderInstructions_[renderIndex++] = value;\n        if (this.hitDetectionEnabled_) {\n          this.hitRenderInstructions_[hitIndex++] = value;\n        }\n      }\n    }\n    /** @type {import('./Layer').WebGLWorkerGenerateBuffersMessage} */\n    var message = {\n      type: _Layer.WebGLWorkerMessageType.GENERATE_BUFFERS,\n      renderInstructions: this.renderInstructions_.buffer,\n      customAttributesCount: this.customAttributes.length\n    };\n    // additional properties will be sent back as-is by the worker\n    message['projectionTransform'] = projectionTransform;\n    this.worker_.postMessage(message, [this.renderInstructions_.buffer]);\n    this.renderInstructions_ = null;\n    /** @type {import('./Layer').WebGLWorkerGenerateBuffersMessage} */\n    if (this.hitDetectionEnabled_) {\n      var hitMessage = {\n        type: _Layer.WebGLWorkerMessageType.GENERATE_BUFFERS,\n        renderInstructions: this.hitRenderInstructions_.buffer,\n        customAttributesCount: 5 + this.customAttributes.length\n      };\n      hitMessage['projectionTransform'] = projectionTransform;\n      hitMessage['hitDetection'] = true;\n      this.worker_.postMessage(hitMessage, [this.hitRenderInstructions_.buffer]);\n      this.hitRenderInstructions_ = null;\n    }\n  };\n  /**\n   * @inheritDoc\n   */\n  WebGLPointsLayerRenderer.prototype.forEachFeatureAtCoordinate = function (coordinate, frameState, hitTolerance, callback, declutteredFeatures) {\n    (0, _asserts.assert)(this.hitDetectionEnabled_, 66);\n    if (!this.hitRenderInstructions_) {\n      return;\n    }\n    var pixel = (0, _transform.apply)(frameState.coordinateToPixelTransform, coordinate.slice());\n    var data = this.hitRenderTarget_.readPixel(pixel[0] / 2, pixel[1] / 2);\n    var color = [data[0] / 255, data[1] / 255, data[2] / 255, data[3] / 255];\n    var index = (0, _Layer.colorDecodeId)(color);\n    var opacity = this.hitRenderInstructions_[index];\n    var uid = Math.floor(opacity).toString();\n    var source = this.getLayer().getSource();\n    var feature = source.getFeatureByUid(uid);\n    if (feature) {\n      return callback(feature, this.getLayer());\n    }\n  };\n  /**\n   * Render the hit detection data to the corresponding render target\n   * @param {import(\"../../PluggableMap.js\").FrameState} frameState current frame state\n   */\n  WebGLPointsLayerRenderer.prototype.renderHitDetection = function (frameState) {\n    // skip render entirely if vertex buffers not ready/generated yet\n    if (!this.hitVerticesBuffer_.getSize()) {\n      return;\n    }\n    this.hitRenderTarget_.setSize([Math.floor(frameState.size[0] / 2), Math.floor(frameState.size[1] / 2)]);\n    this.helper.useProgram(this.hitProgram_);\n    this.helper.prepareDrawToRenderTarget(frameState, this.hitRenderTarget_, true);\n    this.helper.bindBuffer(this.hitVerticesBuffer_);\n    this.helper.bindBuffer(this.indicesBuffer_);\n    this.helper.enableAttributes(this.hitDetectionAttributes);\n    var renderCount = this.indicesBuffer_.getSize();\n    this.helper.drawElements(0, renderCount);\n  };\n  /**\n   * @inheritDoc\n   */\n  WebGLPointsLayerRenderer.prototype.disposeInternal = function () {\n    this.worker_.terminate();\n    this.layer_ = null;\n    this.sourceListenKeys_.forEach(function (key) {\n      (0, _events.unlistenByKey)(key);\n    });\n    this.sourceListenKeys_ = null;\n    _super.prototype.disposeInternal.call(this);\n  };\n  return WebGLPointsLayerRenderer;\n}(_Layer2.default);\nexports.default = WebGLPointsLayerRenderer;\n//# sourceMappingURL=PointsLayer.js.map"},"hash":"c5d28ac68e10f1b33b43c71fab933e1d"}